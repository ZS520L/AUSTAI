{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK4+MR2w+pIJYXbeUekHS4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZS520L/AUSTAI/blob/main/freegpt4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cxoiS_8ATn5",
        "outputId": "a1e526b9-9ed9-4a1a-e2a1-b4d6c1f21a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "成功检索到 2219 条数据！\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import base64\n",
        "from tqdm import tqdm\n",
        "\n",
        "def search_fofa(query, email, key, page):\n",
        "    \"\"\"\n",
        "    :param query: 搜索查询。\n",
        "    :param email: FOFA账户邮箱。\n",
        "    :param key: FOFA API密钥。\n",
        "    :return: 搜索结果。\n",
        "    \"\"\"\n",
        "    base_url = 'https://fofa.info/api/v1/search/all?'\n",
        "    query_enc = base64.b64encode(query.encode()).decode()\n",
        "    params = {\n",
        "        'email': email,\n",
        "        'key': key,\n",
        "        'qbase64': query_enc,\n",
        "        'size': 10000,\n",
        "        'page': page\n",
        "    }\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def test_models(url, models):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    available_models = []\n",
        "    for model in models:\n",
        "        try:\n",
        "            data = {'model': model, 'messages': [{'role':'user', 'content':'苏轼为什么暴打苏东坡？'}], 'stream': True}\n",
        "            response = requests.post(url + '/api/openai' + '/v1/chat/completions', headers=headers, data=json.dumps(data), stream=True)\n",
        "            if response.status_code == 200 and (\"chat.completion.chunk\" in response.text):\n",
        "                # print(response.text,'\\n')\n",
        "                available_models.append(model)\n",
        "        except:\n",
        "            break\n",
        "    return available_models + ['gpt4']\n",
        "\n",
        "models = ['gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-1106', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-1106-preview', 'gpt-4-vision-preview']\n",
        "\n",
        "\n",
        "# 使用示例\n",
        "# email = 'li1u888@163.com'\n",
        "# key = '5dee7d8a386a3ac07079b229fc80142e'\n",
        "\n",
        "email = 'dffjka@open_wechat'\n",
        "key = 'ed28fbd30452c5154aa8e6a5d4232592'\n",
        "query = '\"chat\" && icon_hash=\"1296353639\" && country=\"JP\"'\n",
        "page = 1\n",
        "\n",
        "results = search_fofa(query, email, key, page)\n",
        "try:\n",
        "  print('成功检索到',len(results['results']),'条数据！')\n",
        "except:\n",
        "  print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def extract_content(data_string):\n",
        "    lines = data_string.split(\"\\n\")  # split by newline\n",
        "    content = \"\"\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith('data:'):\n",
        "            try:\n",
        "                data_str = line[6:]  # remove 'data: '\n",
        "                data_json = json.loads(data_str)\n",
        "                choices = data_json.get('choices', [])\n",
        "                for choice in choices:\n",
        "                    delta = choice.get('delta', {})\n",
        "                    content += delta.get('content', '')\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "    return content\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "data = {'model': 'gpt-3.5-turbo', 'messages': [{'role': 'user', 'content': '苏轼为什么暴打苏东坡？'}],'stream':True}\n",
        "\n",
        "if results:\n",
        "    for result in tqdm(results['results']):\n",
        "        link = result[0]\n",
        "        try:\n",
        "            # 替换可变部分的链接\n",
        "            url = link + '/api/openai/v1/chat/completions'\n",
        "            response = requests.post(url, headers=headers, data=json.dumps(data), stream=True, timeout=1)\n",
        "            # 如果状态码为200，表示请求成功\n",
        "            if response.status_code == 200 and (\"chat.completion.chunk\" in response.text):\n",
        "                print('###'*10)\n",
        "                print(extract_content(response.text))\n",
        "                print('接口地址：', link+'/api/openai')\n",
        "                print(\"可用模型：\", test_models(link, models))\n",
        "                with open(\"output.txt\", \"a\") as f:  # \"a\"模式表示追加模式，如果文件不存在，将会创建\n",
        "                    f.write('接口地址：' + link + '/api/openai' + '\\n')\n",
        "                    f.write(\"可用模型：\" + str(test_models(link, models)) + '\\n')\n",
        "                print('###'*10)\n",
        "            else:\n",
        "                # print(f\"Request to {url} failed with status code {response.status_code}\")\n",
        "                pass\n",
        "        except Exception as e:\n",
        "            # print(f\"An error occurred while making a request to {url}: {e}\")\n",
        "            pass\n",
        "else:\n",
        "    print(\"无法获取数据或没有找到匹配结果。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt2dJmVSAf9e",
        "outputId": "8f2641b7-6669-4031-a4fb-2c566f52c33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 623/2219 [01:54<06:35,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##############################\n",
            "èè½¼å¹¶æ²¡ææ´æèä¸å¡ãèä¸å¡ï¼å­å­ç»ï¼åèè½¼ï¼å­å­ç»ï¼æ¯åä¸äººï¼æ¯åå®æ¶æçæå­¦å®¶ãæ¿æ²»å®¶ãä¹¦æ³å®¶ãç¾é£å®¶ç­å¤æ¹é¢æååºä¼çäººç©ãèè½¼åèä¸å¡æ¯åä¸äººçä¸ååå­ï¼ä¸»è¦æ¯å ä¸ºå¶å­å·çååä½¿å¾äººä»¬å¨ä¸ååºåä½¿ç¨ä¸åçåå­ã\n",
            "接口地址： https://xiutie.chat.dplus.tech/api/openai\n",
            "可用模型： ['gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-1106', 'gpt4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 625/2219 [03:05<4:54:05, 11.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##############################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 1570/2219 [05:49<03:46,  2.87it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6GrOo5-AoMp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}